
Start epoch #1, learning rate for this epoch: [0.0002]
Train Epoch: 1 [40/800 (5.0%)]	Loss: 1.6544
Train Epoch: 1 [80/800 (10.0%)]	Loss: 1.5811
Train Epoch: 1 [120/800 (15.0%)]	Loss: 1.5609
Train Epoch: 1 [160/800 (20.0%)]	Loss: 1.6351
Train Epoch: 1 [200/800 (25.0%)]	Loss: 1.6296
Train Epoch: 1 [240/800 (30.0%)]	Loss: 1.5003
Train Epoch: 1 [280/800 (35.0%)]	Loss: 1.5575
Train Epoch: 1 [320/800 (40.0%)]	Loss: 1.4319
Train Epoch: 1 [360/800 (45.0%)]	Loss: 1.6652
Train Epoch: 1 [400/800 (50.0%)]	Loss: 1.7271
Train Epoch: 1 [440/800 (55.0%)]	Loss: 1.6493
Train Epoch: 1 [480/800 (60.0%)]	Loss: 1.4578
Train Epoch: 1 [520/800 (65.0%)]	Loss: 1.4738
Train Epoch: 1 [560/800 (70.0%)]	Loss: 1.4745
Train Epoch: 1 [600/800 (75.0%)]	Loss: 1.5836
Train Epoch: 1 [640/800 (80.0%)]	Loss: 1.4345
Train Epoch: 1 [680/800 (85.0%)]	Loss: 1.6400
Train Epoch: 1 [720/800 (90.0%)]	Loss: 1.6022
Train Epoch: 1 [760/800 (95.0%)]	Loss: 1.5692
Train Epoch: 1 [800/800 (100.0%)]	Loss: 1.5499
Done epoch #1, time for this epoch: 779.6812431812286s
Epoch 1: loss: 1.5999, train accuracy: 5898274.1250, valid accuracy:5931123.0000
=========================END STEP 2=========================
[PROGRESS] STEP 3: Plotting diagrams...
Traceback (most recent call last):
  File "/home/wallace/Code/HUST/UNET/main.py", line 127, in <module>
    utils.result_visualization(model=model, train_dataloader=train_dataloader)
  File "/home/wallace/Code/HUST/UNET/utilities/utils.py", line 77, in result_visualization
    predict = model(img)
  File "/home/wallace/miniconda3/envs/deep_learning_project/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/wallace/miniconda3/envs/deep_learning_project/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/wallace/Code/HUST/UNET/model/unet.py", line 28, in forward
    n1, s1 = self.enc1(image)
  File "/home/wallace/miniconda3/envs/deep_learning_project/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/wallace/miniconda3/envs/deep_learning_project/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/wallace/Code/HUST/UNET/model/encoder.py", line 18, in forward
    x = self.conv1(x)
  File "/home/wallace/miniconda3/envs/deep_learning_project/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/wallace/miniconda3/envs/deep_learning_project/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/wallace/miniconda3/envs/deep_learning_project/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 460, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/wallace/miniconda3/envs/deep_learning_project/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 456, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor