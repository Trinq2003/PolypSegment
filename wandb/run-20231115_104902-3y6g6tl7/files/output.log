
Start epoch #1, learning rate for this epoch: [0.0002]
Train Epoch: 1 [40/800 (5.0%)]	Loss: 1.8204
Train Epoch: 1 [80/800 (10.0%)]	Loss: 1.7412
Train Epoch: 1 [120/800 (15.0%)]	Loss: 1.7068
Train Epoch: 1 [160/800 (20.0%)]	Loss: 1.6933
Train Epoch: 1 [200/800 (25.0%)]	Loss: 1.6056
Train Epoch: 1 [240/800 (30.0%)]	Loss: 1.6346
Train Epoch: 1 [280/800 (35.0%)]	Loss: 1.6296
Train Epoch: 1 [320/800 (40.0%)]	Loss: 1.6308
Train Epoch: 1 [360/800 (45.0%)]	Loss: 1.6017
Train Epoch: 1 [400/800 (50.0%)]	Loss: 1.5603
Train Epoch: 1 [440/800 (55.0%)]	Loss: 1.4101
Train Epoch: 1 [480/800 (60.0%)]	Loss: 1.4879
Train Epoch: 1 [520/800 (65.0%)]	Loss: 1.4827
Train Epoch: 1 [560/800 (70.0%)]	Loss: 1.4184
Train Epoch: 1 [600/800 (75.0%)]	Loss: 1.6303
Train Epoch: 1 [640/800 (80.0%)]	Loss: 1.4968
Train Epoch: 1 [680/800 (85.0%)]	Loss: 1.5164
Train Epoch: 1 [720/800 (90.0%)]	Loss: 1.6683
Train Epoch: 1 [760/800 (95.0%)]	Loss: 1.5711
Train Epoch: 1 [800/800 (100.0%)]	Loss: 1.4972
Done epoch #1, time for this epoch: 84.56251454353333s
Epoch 1: loss: 1.6139, train accuracy: 5419950.5000, valid accuracy:5461157.5000
Start epoch #2, learning rate for this epoch: [0.0002]
Train Epoch: 2 [40/800 (5.0%)]	Loss: 1.3417
Train Epoch: 2 [80/800 (10.0%)]	Loss: 1.4780
Train Epoch: 2 [120/800 (15.0%)]	Loss: 1.4087
Train Epoch: 2 [160/800 (20.0%)]	Loss: 1.5191
Train Epoch: 2 [200/800 (25.0%)]	Loss: 1.3535
Train Epoch: 2 [240/800 (30.0%)]	Loss: 1.4802
Train Epoch: 2 [280/800 (35.0%)]	Loss: 1.5243
Train Epoch: 2 [320/800 (40.0%)]	Loss: 1.5042
Train Epoch: 2 [360/800 (45.0%)]	Loss: 1.4501
Train Epoch: 2 [400/800 (50.0%)]	Loss: 1.2882
Train Epoch: 2 [440/800 (55.0%)]	Loss: 1.3351
Train Epoch: 2 [480/800 (60.0%)]	Loss: 1.5149
Train Epoch: 2 [520/800 (65.0%)]	Loss: 1.3843
Train Epoch: 2 [560/800 (70.0%)]	Loss: 1.5046
Train Epoch: 2 [600/800 (75.0%)]	Loss: 1.5808
Train Epoch: 2 [640/800 (80.0%)]	Loss: 1.3136
Train Epoch: 2 [680/800 (85.0%)]	Loss: 1.3577
Train Epoch: 2 [720/800 (90.0%)]	Loss: 1.5853
Train Epoch: 2 [760/800 (95.0%)]	Loss: 1.2642
Train Epoch: 2 [800/800 (100.0%)]	Loss: 1.4353
Done epoch #2, time for this epoch: 85.70918297767639s
Epoch 2: loss: 1.4663, train accuracy: 5484210.3750, valid accuracy:5499013.5000
Start epoch #3, learning rate for this epoch: [0.0002]
Train Epoch: 3 [40/800 (5.0%)]	Loss: 1.3912
Train Epoch: 3 [80/800 (10.0%)]	Loss: 1.4873
Train Epoch: 3 [120/800 (15.0%)]	Loss: 1.3282
Train Epoch: 3 [160/800 (20.0%)]	Loss: 1.2989
Train Epoch: 3 [200/800 (25.0%)]	Loss: 1.3161
Train Epoch: 3 [240/800 (30.0%)]	Loss: 1.4579
Train Epoch: 3 [280/800 (35.0%)]	Loss: 1.5117
Train Epoch: 3 [320/800 (40.0%)]	Loss: 1.2548
Train Epoch: 3 [360/800 (45.0%)]	Loss: 1.6413
Train Epoch: 3 [400/800 (50.0%)]	Loss: 1.5601
Train Epoch: 3 [440/800 (55.0%)]	Loss: 1.6234
Train Epoch: 3 [480/800 (60.0%)]	Loss: 1.2847
Train Epoch: 3 [520/800 (65.0%)]	Loss: 1.4740
Train Epoch: 3 [560/800 (70.0%)]	Loss: 1.2408
Train Epoch: 3 [600/800 (75.0%)]	Loss: 1.4402
Train Epoch: 3 [640/800 (80.0%)]	Loss: 1.4067
Train Epoch: 3 [680/800 (85.0%)]	Loss: 1.5480
Train Epoch: 3 [720/800 (90.0%)]	Loss: 1.1786
Train Epoch: 3 [760/800 (95.0%)]	Loss: 1.4313
Train Epoch: 3 [800/800 (100.0%)]	Loss: 1.5557
Done epoch #3, time for this epoch: 86.8189845085144s
Epoch 3: loss: 1.4138, train accuracy: 6116718.1250, valid accuracy:6100733.5000
=========================END STEP 2=========================
[PROGRESS] STEP 3: Plotting diagrams...
Traceback (most recent call last):
  File "/home/wallace/Code/HUST/UNET/main.py", line 126, in <module>
    utils.result_visualization(model=model, device=device, train_dataloader=train_dataloader)
  File "/home/wallace/Code/HUST/UNET/utilities/utils.py", line 80, in result_visualization
    arr[i][0].imshow(img[i].permute(1, 2, 0));
  File "/home/wallace/miniconda3/envs/deep_learning_project/lib/python3.10/site-packages/matplotlib/__init__.py", line 1465, in inner
    return func(ax, *map(sanitize_sequence, args), **kwargs)
  File "/home/wallace/miniconda3/envs/deep_learning_project/lib/python3.10/site-packages/matplotlib/axes/_axes.py", line 5756, in imshow
    im.set_data(X)
  File "/home/wallace/miniconda3/envs/deep_learning_project/lib/python3.10/site-packages/matplotlib/image.py", line 723, in set_data
    self._A = self._normalize_image_array(A)
  File "/home/wallace/miniconda3/envs/deep_learning_project/lib/python3.10/site-packages/matplotlib/image.py", line 686, in _normalize_image_array
    A = cbook.safe_masked_invalid(A, copy=True)
  File "/home/wallace/miniconda3/envs/deep_learning_project/lib/python3.10/site-packages/matplotlib/cbook.py", line 733, in safe_masked_invalid
    x = np.array(x, subok=True, copy=copy)
  File "/home/wallace/miniconda3/envs/deep_learning_project/lib/python3.10/site-packages/torch/_tensor.py", line 1030, in __array__
    return self.numpy()
TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.