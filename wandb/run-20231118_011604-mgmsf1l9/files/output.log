
Start epoch #1, learning rate for this epoch: [0.0002]
Train Epoch: 1 [40/800 (5.0%)]	Loss: 6.7385
Train Epoch: 1 [80/800 (10.0%)]	Loss: 6.6572
Train Epoch: 1 [120/800 (15.0%)]	Loss: 6.6486
Train Epoch: 1 [160/800 (20.0%)]	Loss: 6.6258
Train Epoch: 1 [200/800 (25.0%)]	Loss: 6.6179
Train Epoch: 1 [240/800 (30.0%)]	Loss: 6.6065
Train Epoch: 1 [280/800 (35.0%)]	Loss: 6.6095
Train Epoch: 1 [320/800 (40.0%)]	Loss: 6.6012
Train Epoch: 1 [360/800 (45.0%)]	Loss: 6.6122
Train Epoch: 1 [400/800 (50.0%)]	Loss: 6.5973
Train Epoch: 1 [440/800 (55.0%)]	Loss: 6.5959
Train Epoch: 1 [480/800 (60.0%)]	Loss: 6.5971
Train Epoch: 1 [520/800 (65.0%)]	Loss: 6.6019
Train Epoch: 1 [560/800 (70.0%)]	Loss: 6.5969
Train Epoch: 1 [600/800 (75.0%)]	Loss: 6.5944
Train Epoch: 1 [640/800 (80.0%)]	Loss: 6.5950
Train Epoch: 1 [680/800 (85.0%)]	Loss: 6.5932
Train Epoch: 1 [720/800 (90.0%)]	Loss: 6.5927
Train Epoch: 1 [760/800 (95.0%)]	Loss: 6.5931
Train Epoch: 1 [800/800 (100.0%)]	Loss: 6.5929
Done epoch #1, time for this epoch: 142.59865140914917s
Epoch 1: loss: 6.6263, train accuracy: 2257482.7500, valid accuracy:2225429.0000
Start epoch #2, learning rate for this epoch: [0.0002]
Train Epoch: 2 [40/800 (5.0%)]	Loss: 6.5929
Train Epoch: 2 [80/800 (10.0%)]	Loss: 6.5926
Train Epoch: 2 [120/800 (15.0%)]	Loss: 6.5926
Train Epoch: 2 [160/800 (20.0%)]	Loss: 6.5930
Train Epoch: 2 [200/800 (25.0%)]	Loss: 6.5925
Train Epoch: 2 [240/800 (30.0%)]	Loss: 6.5927
Train Epoch: 2 [280/800 (35.0%)]	Loss: 6.5924
Train Epoch: 2 [320/800 (40.0%)]	Loss: 6.5924
Train Epoch: 2 [360/800 (45.0%)]	Loss: 6.5923
Train Epoch: 2 [400/800 (50.0%)]	Loss: 6.5924
Train Epoch: 2 [440/800 (55.0%)]	Loss: 6.5923
Train Epoch: 2 [480/800 (60.0%)]	Loss: 6.5927
Train Epoch: 2 [520/800 (65.0%)]	Loss: 6.5923
Train Epoch: 2 [560/800 (70.0%)]	Loss: 6.5928
Train Epoch: 2 [600/800 (75.0%)]	Loss: 6.5925
Train Epoch: 2 [640/800 (80.0%)]	Loss: 6.5924
Train Epoch: 2 [680/800 (85.0%)]	Loss: 6.5922
Train Epoch: 2 [720/800 (90.0%)]	Loss: 6.5922
Train Epoch: 2 [760/800 (95.0%)]	Loss: 6.5921
Train Epoch: 2 [800/800 (100.0%)]	Loss: 6.5924
Done epoch #2, time for this epoch: 143.96028518676758s
Epoch 2: loss: 6.5925, train accuracy: 1974875.0000, valid accuracy:1996914.0000
Start epoch #3, learning rate for this epoch: [0.0002]
Train Epoch: 3 [40/800 (5.0%)]	Loss: 6.5923
Train Epoch: 3 [80/800 (10.0%)]	Loss: 6.5921
Train Epoch: 3 [120/800 (15.0%)]	Loss: 6.5920
Train Epoch: 3 [160/800 (20.0%)]	Loss: 6.5920
Train Epoch: 3 [200/800 (25.0%)]	Loss: 6.5921
Train Epoch: 3 [240/800 (30.0%)]	Loss: 6.5920
Train Epoch: 3 [280/800 (35.0%)]	Loss: 6.5920
Train Epoch: 3 [320/800 (40.0%)]	Loss: 6.5921
Train Epoch: 3 [360/800 (45.0%)]	Loss: 6.5920
Train Epoch: 3 [400/800 (50.0%)]	Loss: 6.5920
Train Epoch: 3 [440/800 (55.0%)]	Loss: 6.5920
Train Epoch: 3 [480/800 (60.0%)]	Loss: 6.5920
Train Epoch: 3 [520/800 (65.0%)]	Loss: 6.5921
Train Epoch: 3 [560/800 (70.0%)]	Loss: 6.5919
Train Epoch: 3 [600/800 (75.0%)]	Loss: 6.5920
Train Epoch: 3 [640/800 (80.0%)]	Loss: 6.5920
Train Epoch: 3 [680/800 (85.0%)]	Loss: 6.5919
Train Epoch: 3 [720/800 (90.0%)]	Loss: 6.5919
Train Epoch: 3 [760/800 (95.0%)]	Loss: 6.5920
Train Epoch: 3 [800/800 (100.0%)]	Loss: 6.5919
Done epoch #3, time for this epoch: 145.1034369468689s
Epoch 3: loss: 6.5921, train accuracy: 1927242.5000, valid accuracy:1925381.5000
Start epoch #4, learning rate for this epoch: [0.0002]
Train Epoch: 4 [40/800 (5.0%)]	Loss: 6.5920
Train Epoch: 4 [80/800 (10.0%)]	Loss: 6.5920
Train Epoch: 4 [120/800 (15.0%)]	Loss: 6.5919
Train Epoch: 4 [160/800 (20.0%)]	Loss: 6.5920
Train Epoch: 4 [200/800 (25.0%)]	Loss: 6.5920
Train Epoch: 4 [240/800 (30.0%)]	Loss: 6.5919
Train Epoch: 4 [280/800 (35.0%)]	Loss: 6.5920
Train Epoch: 4 [320/800 (40.0%)]	Loss: 6.5919
Train Epoch: 4 [360/800 (45.0%)]	Loss: 6.5919
Train Epoch: 4 [400/800 (50.0%)]	Loss: 6.5919
Train Epoch: 4 [440/800 (55.0%)]	Loss: 6.5919
Train Epoch: 4 [480/800 (60.0%)]	Loss: 6.5919
Train Epoch: 4 [520/800 (65.0%)]	Loss: 6.5919
Train Epoch: 4 [560/800 (70.0%)]	Loss: 6.5919
Train Epoch: 4 [600/800 (75.0%)]	Loss: 6.5919
Train Epoch: 4 [640/800 (80.0%)]	Loss: 6.5919
Train Epoch: 4 [680/800 (85.0%)]	Loss: 6.5921
Train Epoch: 4 [720/800 (90.0%)]	Loss: 6.5919
Train Epoch: 4 [760/800 (95.0%)]	Loss: 6.5919
Train Epoch: 4 [800/800 (100.0%)]	Loss: 6.5919
Done epoch #4, time for this epoch: 149.02016949653625s
Epoch 4: loss: 6.5919, train accuracy: 1921830.1250, valid accuracy:1939918.0000
Start epoch #5, learning rate for this epoch: [0.00012]
Train Epoch: 5 [40/800 (5.0%)]	Loss: 6.5920
Train Epoch: 5 [80/800 (10.0%)]	Loss: 6.5918
Train Epoch: 5 [120/800 (15.0%)]	Loss: 6.5918
Train Epoch: 5 [160/800 (20.0%)]	Loss: 6.5918
Train Epoch: 5 [200/800 (25.0%)]	Loss: 6.5920
Train Epoch: 5 [240/800 (30.0%)]	Loss: 6.5919
Train Epoch: 5 [280/800 (35.0%)]	Loss: 6.5920
Train Epoch: 5 [320/800 (40.0%)]	Loss: 6.5919
Train Epoch: 5 [360/800 (45.0%)]	Loss: 6.5918
Train Epoch: 5 [400/800 (50.0%)]	Loss: 6.5918
Train Epoch: 5 [440/800 (55.0%)]	Loss: 6.5918
Train Epoch: 5 [480/800 (60.0%)]	Loss: 6.5918
Train Epoch: 5 [520/800 (65.0%)]	Loss: 6.5918
Train Epoch: 5 [560/800 (70.0%)]	Loss: 6.5918
Train Epoch: 5 [600/800 (75.0%)]	Loss: 6.5918
Train Epoch: 5 [640/800 (80.0%)]	Loss: 6.5919
Train Epoch: 5 [680/800 (85.0%)]	Loss: 6.5918
Train Epoch: 5 [720/800 (90.0%)]	Loss: 6.5918
Train Epoch: 5 [760/800 (95.0%)]	Loss: 6.5919
Train Epoch: 5 [800/800 (100.0%)]	Loss: 6.5918
Done epoch #5, time for this epoch: 145.42910623550415s
Epoch 5: loss: 6.5919, train accuracy: 1981224.6250, valid accuracy:1981136.5000
=========================END STEP 2=========================
[PROGRESS] STEP 3: Plotting diagrams...
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
Traceback (most recent call last):
  File "/home/wallace/Code/HUST/UNET/main.py", line 171, in <module>
    utils.save_prediction_image(model=model, device=device, test_dataloader=test_dataloader, infer_path=inference_path)
  File "/home/wallace/Code/HUST/UNET/utilities/utils.py", line 108, in save_prediction_image
    for _, (img, path, H, W) in enumerate(test_dataloader):
  File "/home/wallace/miniconda3/envs/deep_learning_project/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/home/wallace/miniconda3/envs/deep_learning_project/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 674, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/wallace/miniconda3/envs/deep_learning_project/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/wallace/miniconda3/envs/deep_learning_project/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/wallace/Code/HUST/UNET/data/test_dataloader.py", line 20, in __getitem__
    data = self.transform(data) / 255
  File "/home/wallace/miniconda3/envs/deep_learning_project/lib/python3.10/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
  File "/home/wallace/miniconda3/envs/deep_learning_project/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/wallace/miniconda3/envs/deep_learning_project/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/wallace/miniconda3/envs/deep_learning_project/lib/python3.10/site-packages/torchvision/transforms/transforms.py", line 277, in forward
    return F.normalize(tensor, self.mean, self.std, self.inplace)
  File "/home/wallace/miniconda3/envs/deep_learning_project/lib/python3.10/site-packages/torchvision/transforms/functional.py", line 361, in normalize
    raise TypeError(f"img should be Tensor Image. Got {type(tensor)}")
TypeError: img should be Tensor Image. Got <class 'PIL.Image.Image'>
=========================END STEP 3=========================
[PROGRESS] STEP 4: Testing...